\chapter{Discussion and Interpretation}
\label{discussion-and-interpretation}

In this chapter,
the results and evaluations which were presented in the previous chapter \ref{evaluation-and-results},
are discussed. The meanings behind the specific results are brought forward in more detail.
Moreover, interpretations and implications of the results and evaluations are presented by the researcher.

%The first and most important topic to be discussed,
%are the learnings from the prototype implementation.

\section*{Learnings From The Prototype Implementation}

In general, the presented design and development of the prototype
showed a possible way on how to provide a solution to the research question.
From the actual implementation of the abstract design in a Kubernetes operator,
and its in-context use in the proof of concept,
certain learnings could be inferred.

\subsection*{User Experience}

Due to \nameref{objective4},
the prototype has been designed to be agnostic to the tooling used, which includes the GitOps engine, the Git provider, and the configuration/templating tool.
While it is good that the prototype can work with many other tools,
and does not force the use of any specific tool for the mentioned components,
the user experience can lack, as a result.

Often times users who want to setup a GitOps workflow,
implement either e.g. Argo or Flux for their primary GitOps tool which also provides the main engine,
which does reconciliation.
When the proposed prototype operator with its according custom resources for environments and promotions
should be set up additionally,
then some information essentially needs to be specified twice. For example,
an environment resource of the prototype operator defines the URL of the Git repository,
which also was needed to be defined for the GitOps engine, e.g. Flux GitRepository or ArgoCD Application.

The access credentials to the Git repository, i.e. the SSH deploy key,
also needs to be setup once for the typically used Flux or Argo GitOps engine,
as well as the promotions operator.

A possible solution to this issue could be to directly integrate with either Flux or Argo - since these are the most popular, and most likely already installed and used by users of the promotions operator.

\subsection*{Security Considerations}

The designed and implemented prototype operator can generally run in any Kubernetes cluster.
It is independent from the deployment environments, so it could either run in the deployment environment itself,
or alternatively in a management cluster, which would then be responsible for the promotion of multiple environments.
However, when the resource dependency for a promotion is a workload or another resource within the environment,
which is to be promoted, it makes sense to have the operator run inside the same deployment environment, i.e. Kubernetes cluster or namespace, as what is specified in the Environment custom resource.

The goal with the promotion resource is generally to specify two environments,
a source and a target environment.
While the source environment typically would be the same environment in which the operator runs in,
the target environment would just represent the Git repository of the target cluster/namespace.
This raises some security considerations,
since the operator can read and write to the target environment's desired state, i.e. Git repository.
This means, that the operator running in a certain environment would have read and write access
to the specified target environment of the promotion.
With this setup, bad actors who have access to the specified environment resources state,
could change the desired state in such a way, that
potentially harmful applications are deployed to the other environment.
Since the operator needs appropriate permissions for the environment's Git repository,
in order to raise pull requests and push to pull request branches, the operator could
be a potential security issue.

\subsection*{Use at Scale}

The use of the promotions operator prototype at scale needs to be addressed.
Using the operator at scale could either be to install the operator in a separate management cluster,
or to install the operator in each environment.
In order for the dependency capability of the promotion controller
to be able to check for dependent resources within an environment,
which is a source environment for a promotion,
the operator ideally should be running inside this same environment, i.e. cluster/namespace.

When installing the promotions operator once in a management cluster/namespace,
in order to handle all or many environment promotions,
the user would save time on the initial setup of the custom resources, deploy keys and API tokens.
However with this approach, it would also mean that the operator running in a completely separated management cluster, typically has no direct access to observe the resources of an environment.

\subsection*{Abstractions}

The proposed prototype provides two main abstractions,
one for the environment,
and one for the promotion.
Usually such a custom resource object represents a resource in the real world.

Although not part of the proposed design and implementation of the prototype,
it would make sense to provide more abstractions.
For example, this could be to divide the environment resource into
a DeploymentEnvironment resource, which would represent a Kubernetes cluster or namespace,
and a GitOpsRepository resource, which would represent the according GitOps repository (the desired state definition).
It is always a good practice to have custom resources represent a real tangible resource,
and not stand for multiple things in the real world.

\subsection*{Modularity}

In addition to the topic of abstractions mentioned previously,
it could be beneficial to split up the Promotion custom resource.
There could be a PromotionPolicy resource,
which would define the policy and rules,
when the operator should promote and create a Promotion resource.
The Promotion resource would then only run once to completion.














\section*{Alternative Approaches for Promoting Releases}

Interview partner 1 discussed an alternative approach for handling the promotion process in GitOps environments.
This was presented in section \ref{insights-related-ideas-approaches}.

The main idea of this approach is that long-living environments are not necessary,
and the resiliency should rather be created by doing progressive delivery,
not just for the user-facing application or service,
but for the whole infrastructure stack below.
This has the purpose of further increasing the immutability and resiliency of a service.
Since the amount of supporting and infrastructure services and dependencies are increasing with Kubernetes,
and each having a version and constantly new releases, and the possibility of breaking the actual important
service that is user-facing.

When following this approach, the end goal is to create a complete copy of the production environment,
and then do progressive delivery on that.
Once the release is marked as good, the old production environment can safely be destroyed.
With the GitOps pattern, and the application and infrastructure being stored in Git,
this has become increasingly more possible.
Also tools like the Weave GitOps Terraform Controller have contributed to the enablement of this new approach. 

While, with this approach, the need for long-living environments decreases,
whole copies of production environments will still need to be created.
This means there is no guarantee that the cost will decrease.
Advanced tactics like auto-scaling will need to be implemented, in order to
keep costs low of potentially high numbers of dynamically created environments.





































%
%\section{Instruction included in the original FHBgld word processor template}
%Die Ergebnisse der Arbeit sind in übersichtlicher Form darzustellen Die gewählte Form der Darstellung ist vom gewählten Datenmaterial und den in der Einleitung gesetzten Zielen abhängig. Die Ergebnisse sind zu interpretieren und in Bezug zum Stand des Wissens zu diskutieren. Über die Beantwortung der Forschungsfrage und die daraus gezogenen Schlussfolgerungen schließt sich der Bogen zur Einleitung. 
%
%Wichtig ist die gedanklich klare Unterscheidung zwischen der Darstellung der Ergebnisse und der Interpretation/Bewertung der Ergebnisse. 
%
%\section{Code}
%If you want to show program code within your thesis you can use the \verb|\texttt{verbatim}| environment or for a more complex display take a look at \url{https://www.overleaf.com/learn/latex/Code_listing}
%
%\begin{verbatim}
%	Text enclosed inside \texttt{verbatim} environment 
%	is printed directly 
%	and all \LaTeX{} commands are ignored.
%\end{verbatim}
%
%\begin{lstlisting}[language=Python, caption=Python example]
%	import numpy as np
%	
%	def incmatrix(genl1,genl2):
%	m = len(genl1)
%	n = len(genl2)
%	M = None #to become the incidence matrix
%	VT = np.zeros((n*m,1), int)  #dummy variable
%	
%	#compute the bitwise xor matrix
%	M1 = bitxormatrix(genl1)
%	M2 = np.triu(bitxormatrix(genl2),1) 
%	
%	for i in range(m-1):
%	for j in range(i+1, m):
%	[r,c] = np.where(M2 == M1[i,j])
%	for k in range(len(r)):
%	VT[(i)*n + r[k]] = 1;
%	VT[(i)*n + c[k]] = 1;
%	VT[(j)*n + r[k]] = 1;
%	VT[(j)*n + c[k]] = 1;
%	
%	if M is None:
%	M = np.copy(VT)
%	else:
%	M = np.concatenate((M, VT), 1)
%	
%	VT = np.zeros((n*m,1), int)
%	
%	return M
%\end{lstlisting}
